# HDFS Commands, Big Data Development & MapReduce â€“ Clean Notes

---

## ğŸ“‚ HDFS Commands

â†’ `hdfs dfs`  
- Used before executing any HDFS command

â†’ Create directory
```bash
hdfs dfs -mkdir <dir_name>
````

â†’ Copy file from Linux to HDFS

```bash
hdfs dfs -copyFromLocal <local_path> <hdfs_path>
```

Notes:

* Copying to `/home` in Linux may require permission changes
* First navigate to the Linux directory where the file exists, then copy to HDFS

---

### Directory & File Checks

â†’ List directories

```bash
hdfs dfs -ls /
```

â†’ Check if file exists in a directory

```bash
hdfs dfs -ls /<path>
```

---

### Disk & Cluster Information

â†’ Check HDFS space

```bash
hdfs dfs -df
```

â†’ Check HDFS health

```bash
hdfs fsck /
```

â†’ Check Hadoop version

```bash
hadoop version
```

---

### File Operations

â†’ Create empty file

```bash
hdfs dfs -touchz <file_path>
```

â†’ View file content

```bash
hdfs dfs -cat <file_path>
```

â†’ Copy file from HDFS to local (Linux)

```bash
hdfs dfs -copyToLocal <hdfs_path> <local_path>
```

â†’ Move file from Linux to HDFS (cut + paste)

```bash
hdfs dfs -moveFromLocal <local_path> <hdfs_path>
```

---

## ğŸ—ï¸ Big Data Development Stages

```
RDBMS
   â†“
Ingestion
   â†“
Storage (HDFS / Cloud)
   â†“
Processing (Hive, Spark, Storm, Pig, MapReduce)
   â†“
Visualization (Tableau, Power BI, Business Objects)
```

Cloud Storage Examples:

* Amazon S3
* Azure Blob
* Google Cloud Storage

---

### Ingestion

â†’ Process of getting data from various sources into big data storage
â†’ One common ingestion tool: **Sqoop**
â†’ Moves data from RDBMS to HDFS

After ingestion:

* Data is distributed into **blocks**

---

### Processing

â†’ Data is processed based on **business needs**

---

## ğŸ§® MapReduce

â†’ Programming model for **distributed processing**

### Two Stages

#### 1ï¸âƒ£ Map

* Takes input (table, file)
* Produces **keyâ€“value pairs**
* Executed in parallel

#### 2ï¸âƒ£ Reduce

* Takes map output
* Combines values for the same key
* Produces final output

---

### MapReduce Execution Flow

â†’ Mappers work in parallel
â†’ Within each mapper, data is processed sequentially
â†’ Mapper output is **keyâ€“value pairs**
â†’ Results are passed to reducers
â†’ Reducers group values by key and aggregate

---

## âš™ï¸ MapReduce Implementation

â†’ Map logic runs inside **Mapper class**

### Data Types

1. Input key type
2. Input value type
3. Output key type
4. Output value type

â†’ Reduce logic runs inside **Reducer class**

---

### Cluster Execution

â†’ Mapper & Reducer run on individual nodes
â†’ Logic is submitted to the cluster
â†’ Code is distributed to all nodes

Cluster Management:

* Managed by **YARN**
* YARN allocates hardware resources (CPU, RAM)
* Provides resources to mappers & reducers

---

## ğŸ”¢ Number of Mappers & Reducers

â†’ **Number of Mappers**

* Equal to number of data partitions (blocks)
* Decided by the storage system

â†’ **Number of Reducers**

* Default: **1**
* Can be configured by user
* Depends on:

  * Data size
  * Performance optimization

---

### Partitioning Logic

â†’ All mapper output data goes to partitions
â†’ If reducers increase, partitions increase
â†’ Example:

* Reducer = 1 â†’ Partition 1
* Reducer = 2 â†’ Partition 1 & Partition 2

---

## ğŸ”„ Shuffle, Sort & Partitioning

â†’ **Partition**

* Determines which reducer a key goes to
* Uses hash partitioning

â†’ **Shuffle**

* Moves data from mappers to reducers

â†’ **Sort**

* Sorts data by key before reducer execution

---

## â• MapReduce Combiner

â†’ Runs **after Mapper and before Reducer**

```
Mapper â†’ Combiner â†’ Reducer
```

### Purpose

* Combines values with the same key locally
* Reduces data transferred to reducer

Notes:

* Combiner logic is similar to reducer
* Improves parallelism
* Reduces network I/O

âš ï¸ Use combiner carefully:

* Output should not change
* Not suitable for all operations (e.g., average calculation)

---

## âœ… Advantages of Combiner

1. Improves parallelism
2. Reduces data transfer

---

## âš ï¸ Important Notes

â†’ Reducer logic should **not always be used directly as combiner**
â†’ Output must remain correct
â†’ For averages, combiner & reducer logic differ
