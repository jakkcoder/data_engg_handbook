# Apache Hive â€“ Clean Notes

---

## â±ï¸ Latency
â†’ Latency = **delay time**

---

## ğŸ Hive Overview

â†’ Open-source **data warehouse** tool  
â†’ Works on top of **HDFS**  
â†’ Requires:
- HDFS
- YARN
- MapReduce

â†’ Hive **stores data in HDFS**  
â†’ Hive processes data by **converting queries into MapReduce jobs**  
â†’ HQL (Hive Query Language) is used to interact with Hive  
â†’ Hive exposes files in HDFS as **tables** to the user  
â†’ Hive **abstracts MapReduce complexity** from the user

---

## ğŸ†š Hive vs RDBMS

| Hive | RDBMS |
|-----|------|
| Large datasets | Small datasets |
| Parallel computation | Serial computation |
| High latency | Low latency |
| Read-heavy operations | Heavy read/write |
| Not ACID compliant | ACID compliant |
| Disk-based, cheap storage | Expensive storage |
| Batch processing | Transactional processing |

Notes:
- Hive has high latency because it processes data through MapReduce
- Hive does **not own the data**; data is stored in HDFS
- Limited update operations allowed in Hive
- Subqueries are less used
- Joins are limited
- Fewer constraints compared to RDBMS

---

## ğŸ—ï¸ Hive Architecture

### 1ï¸âƒ£ Hive Server
â†’ Entry point when a query is submitted

### 2ï¸âƒ£ Driver
â†’ Receives the query from user  
â†’ Creates session handle  
â†’ Sends query to compiler

### 3ï¸âƒ£ Compiler
â†’ Parses the query  
â†’ Performs semantic analysis  
â†’ Creates execution plan (DAG â€“ Directed Acyclic Graph)

### 4ï¸âƒ£ Metastore
â†’ Stores metadata about:
- Tables
- Columns
- Databases
â†’ Acts as a bridge between:
- Data stored in HDFS
- Tables exposed to users

â†’ Any database with a **JDBC driver** can be used as a metastore

### 5ï¸âƒ£ Execution Engine
â†’ Executes the execution plan  
â†’ Plan is executed in the form of DAG

---

## ğŸ§‘â€ğŸ’» Hive Interfaces

â†’ Hive CLI  
â†’ Beeline CLI

```bash
beeline -u jdbc:hive2://
````

---

## ğŸ§  Key Difference

â†’ Hive works on **distributed data**
â†’ RDBMS works on **centralized data**

---

## ğŸ§¾ Hive Data Types

### Primitive Types

â†’ **Boolean**

â†’ **Numeric**

* Tinyint
* Smallint
* Int
* Bigint
* Float
* Double
* Decimal (defines precision)

â†’ **String Types**

* String â†’ unbounded length (most used in Big Data)
* Char
* Varchar

â†’ **Timestamp**

* Stored as integer
* Can also be treated as string

â†’ **Date**

---

## ğŸ“¦ Data Storage in Hive

â†’ When tables are created in Hive, data is stored in HDFS under:

```
/user/hive/warehouse
```

### Directory Structure

```
DB_NAME.db
   â†“
TABLE_NAME
   â†“
Data files stored in table
```

â†’ Everything is stored inside **HDFS**

---

## ğŸ“Š Hive Tables

### Managed Table

â†’ Data is **managed by Hive**
â†’ Stored in Hive warehouse directory
â†’ When table is dropped:

* Metadata is deleted
* Data is also deleted

---

### External Table

â†’ Data is **not managed by Hive**
â†’ Data stored **outside warehouse directory**
â†’ External path defined explicitly
â†’ When table is dropped:

* Only metadata is deleted
* Data remains intact

---

### Temporary Table

â†’ Exists only for current Hive session
â†’ Does **not support**:

* Partition
* Index

---

## ğŸ“¥ Inserting Data into Hive Tables

### Standalone Mode

#### From Files

â†’ Step 1: Copy file from Linux to HDFS

```bash
hdfs dfs -copyFromLocal <file> <hdfs_path>
```

â†’ Step 2: Load data from HDFS to Hive table

```sql
LOAD DATA INPATH '<hdfs_path>' INTO TABLE table_name;
```

---

### From Other Tables

â†’ Insert data directly from one Hive table to another

---

### Managed Table Data Load

â†’ After loading data:

* File is **moved** into Hive warehouse directory
* Data is deleted from original HDFS location

---

### External Table Data Load

â†’ Provide HDFS path at table creation
â†’ Data present in HDFS is automatically mapped
â†’ No data movement happens

---

## ğŸ†š Managed vs External Table

| Managed Table               | External Table             |
| --------------------------- | -------------------------- |
| Data inside warehouse       | Data outside warehouse     |
| Hive manages data           | Hive manages only metadata |
| Dropping table deletes data | Dropping table keeps data  |
| Path auto-managed           | Path defined by user       |

Example paths:

**Managed**

```
/user/hive/warehouse/db/table/file.txt
```

**External**

```
/path/in/hdfs/file.txt
```

---

## âœ… Summary

* Hive is best for **batch analytics**
* Built on top of Hadoop ecosystem
* Not suitable for low-latency transactions
* Ideal for large-scale data processing

---
