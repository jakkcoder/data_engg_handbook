# Hadoop Ecosystem & HDFS â€“ Clean Notes

---

## ğŸ˜ Hadoop Ecosystem

â†’ Hadoop ecosystem is a collection of tools used for **distributed storage and processing**

---

## ğŸ§® MapReduce

â†’ A **programming model** in the Hadoop ecosystem  
â†’ Used to perform **distributed processing**

Notes:
- Higher-level components â†’ interactivity
- Lower-level components â†’ storage & scheduling

---

## ğŸ§± Hadoop Components

â†’ **HDFS**
- Scalable storage
- Stores large number of files
- Handles fault tolerance
- Distributed File System

â†’ **YARN (Yet Another Resource Negotiator)**
- Resource management & scheduling

â†’ **Hive**
- Open-source data warehouse
- SQL-like querying

â†’ **Pig**
- Data cleansing and transformation

â†’ **Giraph**
- Graphical / graph processing

â†’ **Storm**
- In-memory / real-time processing tool

â†’ **Spark**
- Fast in-memory processing engine

â†’ **MongoDB**
- NoSQL data source

â†’ **Cassandra**
- Distributed NoSQL database

â†’ **Zookeeper**
- Mainly used for configuration management

---

## ğŸ“‚ HDFS (Hadoop Distributed File System)

â†’ Used for **storage**
â†’ Files are stored in a **distributed manner**

### Key Characteristics
- Everything in HDFS is a **file**
- Built on **commodity hardware**
- Highly fault tolerant
- Optimized for **batch processing**
- High throughput (not low latency)
- Supports very large datasets

---

## ğŸ—„ï¸ File Storage in HDFS

â†’ Manages file storage across multiple disks  
â†’ Disks are spread across machines in a cluster

---

## ğŸ§© HDFS Nodes

```

```
      HDFS Node
       /     \
 NameNode   DataNode
```

```

### NameNode
- Stores **metadata**
- Maintains file system namespace
- Stores directory structure
- Determines mapping of blocks to DataNodes
- Executes file system operations
- Table of contents of HDFS

### DataNode
- Stores **actual data**
- Physically stores data blocks
- Performs block creation and deletion
- Handles read/write requests
- Reports back to NameNode

---

## ğŸ“¦ Storing a File in HDFS

â†’ Distributed files are split into **blocks (data partitions)**

### Block Size
- Default block size: **128 MB**
- Large block size reduces seek time

Effects:
- Increasing block size â†’ reduces parallelism
- Increasing number of blocks â†’ increases parallel processing
- Too many blocks â†’ increases NameNode metadata load

---

## ğŸ“– Reading a File in HDFS

â†’ Metadata from **NameNode** is used  
â†’ NameNode provides location of DataNodes  
â†’ Client directly reads data from DataNodes

---

## âš ï¸ Challenges in Distributed Systems

- Failure of NameNode â†’ metadata loss
- Failure of DataNode â†’ data loss

---

## ğŸ›¡ï¸ Managing DataNode Failure

â†’ Use **Replication**

### Replication Factor
- Number of times data is replicated
- Default replication factor in Hadoop: **3**

Replication Strategy:
- Replicas stored on different machines
- Balance between:
  - Redundancy (fault tolerance)
  - Bandwidth usage

---

### Rack Awareness

â†’ Read requests are routed to the **nearest rack**
â†’ Improves performance
â†’ Reduces network bandwidth usage
â†’ Data is distributed across racks for fault tolerance

---

## ğŸ§  Managing NameNode Failure

â†’ Hadoop uses **replication at NameNode level**

### NameNode Files
1. **fsimage**
   - Snapshot of the complete file system at cluster startup

2. **edits**
   - Log of all file system changes during runtime

â†’ These two together construct the NameNode state

---

## ğŸ”„ Merging fsimage and edits

â†’ Resource-intensive and time-consuming process

Why merging is required:
- To ensure consistency
- Prevent users from accessing incorrect data

Process:
- Secondary NameNode performs merging
- Merges `fsimage` with `edits`
- This process is called **Checkpointing**

---

### Checkpointing Details

- Happens periodically
- Default interval: **1 hour**
- Interval can be configured

---

## ğŸ” Replica Updates

â†’ When one replica is updated:
- Other replicas are updated asynchronously
- Replicas are stored at different locations

---

## ğŸ”” Heartbeat Mechanism

â†’ DataNodes keep sending **heartbeat signals** to NameNode

If heartbeat fails:
- DataNode contacts **Secondary NameNode**
- Secondary NameNode can take over
- Supports high availability

---

## ğŸš€ Summary

- Hadoop focuses on **high throughput**, not low latency
- Designed for **cheap storage + massive scale**
- Fault tolerance achieved using:
  - Replication
  - Rack awareness
  - Checkpointing
