# Apache Kafka â€“ Messages, Topics, Partitions, Brokers & Consumers (Clean Notes)

---

## ðŸ“© Kafka Messages

â†’ Kafka treats **each message as an array of bytes**  
â†’ **Size limit exists** for a message in Kafka  
â†’ Default maximum message size is **1 MB**, but it is **configurable**
  (can be increased or decreased)

---

## ðŸ§¾ Message Content

A Kafka message contains:

- **Key**
  â†’ Defined by the producer  
  â†’ Optional (not mandatory)

- **Value**
  â†’ Actual message content  
  â†’ Stored as a **byte array**  
  â†’ Semantics are decided by the producer / consumer

- **Timestamp**
  â†’ Time at which the message is produced

- **Headers**
  â†’ Optional metadata

---

### Event Time vs Ingestion Time

- **Event Time**
  â†’ Time at which the message is produced

- **Ingestion Time**
  â†’ Time at which the Kafka broker timestamps the data  
  â†’ Time when data is ingested into the Kafka cluster

---

### Messages Without Key

â†’ If a message does **not have a key**, Kafka **automatically generates a key**

---

## ðŸ§µ Kafka Topics

â†’ Producers can publish messages to **multiple topics**  
â†’ Consumers can consume messages from **multiple topics**

â†’ **Topic**
- Logical entity that holds messages
- Identified by a **unique name**
- Records are published to topics

Analogies:
- Topic â‰ˆ table with records
- Topic â‰ˆ queue for similar messages

â†’ Similar producers publish messages to the same topic  
â†’ Similar consumers consume messages from that topic

---

## ðŸ‘¥ Topic Subscription Model

â†’ Topics in Kafka are **multi-subscriber by default**

A topic can have:
- Zero consumers
- One consumer
- Many consumers

---

## ðŸ§© Partitions

```

Group of messages  â†’ Partition
Group of partitions â†’ Topic

```

â†’ Partitioning is a **physical concept**  
â†’ Partitions allow Kafka to:
- Scale horizontally
- Support parallelism

---

## ðŸ“¥ Consumer API

â†’ A consumer is an application that **reads data from Kafka cluster**

Examples:
- Log file readers
- Real-time aggregators
- Data archivers

---

## ðŸ”€ Ways to Consume Data

```

Consume
/        
Batch     Streaming

```

### Batch
â†’ Producer publishes data  
â†’ Consumer consumes data **at its own pace**

### Streaming
â†’ Data is consumed **as soon as it is produced**

---

## ðŸ“Œ Offset Management

â†’ Consumers manage the **offset** of the data  
â†’ Offset decides **from where** a consumer starts reading

â†’ Consumers can:
- Start from a specific offset
- Resume from last committed offset

â†’ Consumers must send **acknowledgement** to the broker

---

## ðŸ§± Kafka Broker

â†’ Kafka is essentially a **broker-based system**  
â†’ Broker is the **brain of Kafka**

Responsibilities of a broker:
- Receives messages from producers
- Stores messages locally in **logs**
- Keeps track of active consumers
- Maintains heartbeat with consumers
- Manages topic partitions
- Manages lifecycle of topics

â†’ **Multiple brokers together form a Kafka cluster**

---

## ðŸ“‚ Logs in Kafka

â†’ Producers send data to Kafka cluster  
â†’ Logs store data **event by event** from producers  

Characteristics:
- Logs are **physical files**
- Managed by Kafka brokers
- Each broker has an assigned **log directory**
- Logs are **opened periodically**
- Old data is **pruned or flushed** after a configured number of days

---

## ðŸ§± Partitions (Detailed)

â†’ Partition = ordered, immutable sequence of records  
â†’ Continuously appended

Key points:
- Each topic can have **one or more partitions**
- Number of partitions is defined during topic creation
- Increasing partitions improves **scalability**
- Each partition has its **own physical log file**

---

### Writing to a Partition

â†’ When a producer writes a message:
- Message is sent to the **leader broker** of that partition
- Leader handles log updates

â†’ Each published message:
- Is written to **only one partition**
- For fault tolerance, partitions are **replicated**
- Replicas are stored on **other brokers**

â†’ **Message ordering is guaranteed within a partition**

---

## ðŸ”¢ Partition Assignment

â†’ Kafka uses a **hashing function** to decide partition placement  
â†’ Kafka does **not** create partitions dynamically

---

## ðŸ‘¥ Consumer Groups

â†’ When data volume is high and a single consumer is slow:
- Multiple consumers are grouped together

â†’ **Consumer Group**
- Single logical unit
- Shares the workload of a topic

Rules:
- Each message is sent to **only one consumer** in a group
- Each partition is consumed by **only one consumer** in a group

---

## ðŸ”„ Load Rebalancing

â†’ Kafka brokers track consumers  
â†’ If a consumer goes down:
- Kafka **rebalances partitions**
- Workload is redistributed among remaining consumers

---

## ðŸ§® Offset Management (Detailed)

â†’ Mechanism to track:
- Which messages are delivered
- Which messages are yet to be processed

â†’ This mechanism is called **Offset Management**

â†’ Consumers are responsible for:
- Maintaining
- Committing
- Managing offsets

---

## âœ… Summary

- Kafka messages are byte arrays with optional keys and headers
- Topics logically group similar messages
- Partitions enable scalability and parallelism
- Brokers store data in logs and manage cluster state
- Consumer groups share workload efficiently
- Offsets track consumption progress
- Load rebalancing ensures fault tolerance
