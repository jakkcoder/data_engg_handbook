# Oozie & Spark Streaming â€“ Clean Notes

---

## ğŸ§­ Oozie (Scheduler)

â†’ Part of the **Hadoop Ecosystem**  
â†’ Used to **schedule, execute, and manage Hadoop jobs** in a distributed environment  

Supported job types:
- MapReduce jobs
- Hive jobs
- Pig jobs
- Shell jobs

---

### Responsibilities of Oozie

â†’ Allows combining multiple complex jobs into a **sequential workflow**  
â†’ Responsible for **triggering workflow actions**  
â†’ Uses Hadoop execution engine to **actually execute tasks**

---

## ğŸ“‚ Types of Oozie Jobs

1. **Oozie Workflow Jobs**
2. **Oozie Coordinator Jobs**
3. **Oozie Bundle**

---

## ğŸ” Oozie Workflow Jobs

â†’ Workflow is a **sequence of actions**  
â†’ Represented as a **DAG (Directed Acyclic Graph)**  
â†’ Specifies the **order of execution**

### Workflow Structure

â†’ Workflow **always starts with `<start>` tag**  
â†’ Workflow **always ends with `<end>` tag**

```

Workflow
/        
Controls    Actions

```

---

### Control Nodes (control the workflow)

- `start`
- `decision`
- `fork` â†’ multiple paths in parallel
- `join`
- `end`
- `kill`

---

### Action Nodes (actual execution)

- Hive job
- Shell job
- Pig job

---

### Workflow Characteristics

â†’ Workflow can be **parameterized**  
â†’ Hardcoding values is **not necessary**

---

## â±ï¸ Synchronous vs Asynchronous

â†’ **Synchronous**
- Tasks executed one after another
- Caller waits for completion

â†’ **Asynchronous**
- Tasks executed independently
- Caller does not wait

---

## ğŸ”€ Workflow Execution Types

â†’ Oozie workflow supports **two execution types**:
- Synchronous
- Asynchronous

---

## ğŸ“Œ States of a Workflow

- Succeeded
- Suspended (environmental issues)
- Killed (manual termination)
- Failed
- Running

---

## â° Oozie Coordinator Jobs

â†’ Workflow triggered by **time and/or data availability**  
â†’ Example:
- Run job every hour
- Trigger when data arrives

---

## ğŸ“¦ Oozie Bundle

â†’ Logical grouping of:
- One or more workflows
- One or more coordinators

â†’ Used to manage **related jobs together**

---

# ğŸŒŠ Spark Streaming

---

## ğŸ”„ What is Stream Processing?

â†’ Processing data **as it is being generated**  
â†’ Input data is **unbounded**
â†’ No predefined beginning or end  

Example:
- Credit card transactions

---

### Continuous Applications

â†’ Can perform:
- Batch processing
- Stream processing
- Interactive processing

---

## ğŸ“Œ Use Cases of Spark Streaming

- Notification & alerting
- Real-time reporting
- Incremental ETL
- Real-time decision making (e.g., Google Maps)
- Online Machine Learning

---

## âœ… Advantages of Stream Processing

â†’ **Lower latency** compared to batch processing

---

## âš ï¸ Challenges of Stream Processing

- Maintaining large amounts of state
- Supporting high data throughput
- Handling **out-of-order data**
- Responding with low latency
- Joining streaming data with external storage
- Updating business logic dynamically

---

# ğŸ§± Structured Streaming

---

## ğŸ“˜ What is Structured Streaming?

â†’ Structured Streaming provides:
- **End-to-end exactly-once semantics**
- **Fault tolerance** via checkpointing

â†’ Treats streaming data as a **continuously growing table**

---

### Key Properties

â†’ Most transformations are **similar to batch processing**  
â†’ Spark handles **incremental processing internally**

---

## ğŸ§  Core Concepts of Structured Streaming

### Transformations & Actions
â†’ Same transformations as batch  
â†’ **Only one action** is supported: writing the stream

---

### Input Sources

Supported sources include:
- Apache Kafka
- Files (HDFS, S3, etc.)
- Distributed file systems
- Socket source (for testing)

---

### Sink

â†’ Destination where output is written  
â†’ Examples:
- Kafka
- File system
- Console sink

---

### Execution Engine

â†’ Responsible for:
- Tracking progress
- Managing state
- Ensuring fault tolerance

---

### Output Modes

â†’ Defines **how data is written to the sink**

---

### Triggers

â†’ Define **when data is written**
â†’ Example:
- Every X seconds
- Once
- Continuous

---

### Event-Time Processing

â†’ Supports **event-time semantics**  
â†’ Data processed based on **timestamp in record**  
â†’ Handles **late-arriving and out-of-order data**

---

## ğŸ”Œ Supported Sinks

- Apache Kafka
- Any file format
- Console sink

---

## âœ… Summary

- Oozie is used for workflow scheduling in Hadoop
- Workflows are DAG-based with control and action nodes
- Coordinators trigger workflows based on time/data
- Spark Streaming processes unbounded data in real time
- Structured Streaming offers exactly-once semantics
- Event-time processing handles late and out-of-order events
