# Structured Streaming (Advanced) & Apache Kafka â€“ Clean Notes

---

## ğŸ§© Output Modes (Structured Streaming)

â†’ Output mode depends on **source and sink**

### Supported Output Modes

- **Append**
  â†’ Append only **new records**
- **Update**
  â†’ Update **changed records**
- **Complete**
  â†’ Rewrite the **entire output**

---

## â±ï¸ Event-Time Processing

### Event-Time Data

â†’ Event time refers to the **time embedded in the data itself**  
â†’ Instead of processing data based on when it **reaches the system**,
   data is processed based on **when it was generated**

---

### Watermark

â†’ Feature of streaming systems  
â†’ Defines **how late** data is expected to arrive  
â†’ Used to handle **late-arriving events** in event-time processing

---

# ğŸŸ¦ Apache Kafka

---

## ğŸ“© What is Kafka?

â†’ A **unified messaging system**  
â†’ Makes data pipelines **reliable, efficient, and manageable**  
â†’ Originally developed by **LinkedIn**

---

## ğŸ§  Why Kafka?

â†’ Used for building **real-time data pipelines**  
â†’ Used for **streaming applications**  
â†’ Highly scalable and fault-tolerant messaging system  

---

## âš™ï¸ Kafka Characteristics

- Scalability
- Availability
- Performance
- Zero downtime
- Extensibility (many connectors available)
- Replication

---

## ğŸ“Œ When Kafka is Used

- Real-time & batch data processing
- Application logs
- Event-driven architectures

---

## ğŸ”¥ Capabilities of Kafka

â†’ **Publish & subscribe** to streams of records  
â†’ Store streams of records in a **fault-tolerant and durable** way  
â†’ Decouples **data producers** from **data consumers**

â†’ Producer speed and consumer speed can be **different**  
â†’ Kafka stores data until it is consumed

---

## ğŸŒŠ Kafka as a Stream

â†’ Kafka represents data as a **continuous stream of records**  
â†’ Streams are:
- Ordered
- Immutable
- Append-only

---

## ğŸ” Data Flow in Kafka

â†’ Streaming data flows from **source â†’ destination**  
â†’ Supports:
- Ingestion
- Transformation
- Distribution of streaming data

---

## ğŸ§± Kafka Components

### Producer (Publisher)
â†’ Sends messages to Kafka topics

### Consumer (Subscriber)
â†’ Reads messages from Kafka topics

### Broker
â†’ Kafka server  
â†’ Receives messages from producers  
â†’ Stores messages and serves them to consumers

---

## ğŸ§ª Kafka Core APIs

- **Producer API**
  â†’ Publish streams of records

- **Consumer API**
  â†’ Subscribe to topics and consume records

- **Streams API**
  â†’ Transform streams of data  
  â†’ Used for **bigger transformations**

- **Connector API**
  â†’ Kafka Connect  
  â†’ Push data to/from external systems

---

## ğŸ”Œ Kafka Connect

â†’ Used to move data **between Kafka and external systems**  
â†’ Useful when:
- Data needs to be pushed after a specific time
- External systems need Kafka data

---

## ğŸ”„ Kafka Streams API

â†’ Allows an application to:
- Consume from one or more topics
- Process the stream
- Produce results to one or more output topics

---

## ğŸŒ Language & Communication

â†’ Kafka communication happens over **language-agnostic TCP protocol**  
â†’ Language does **not matter** (Java, Python, etc.)

---

# ğŸ“¤ Producer API (Detailed)

---

## ğŸ‘¤ Who Can Be a Producer?

Examples:
- Web servers publishing click events
- Log scrubbers pushing log messages
- Sensors pushing telemetry data

---

## ğŸ” Producer Characteristics

- Multiple concurrent producers can write to the same topic
- Producer must specify a **message key** (e.g., `Cust_ID`)
- Messages are serialized into **byte arrays**

---

## ğŸ“¡ Publishing Options

```

Publishing Options
/          
Synchronous   Asynchronous

```

### Synchronous
â†’ Producer waits for **acknowledgement**

### Asynchronous
â†’ Producer does **not wait** for acknowledgement

---

## â“ What Does a Producer Publish?

â†’ Publishes a **stream of data** to Kafka cluster  

Terminology:
- Published data = **Message**
- Message is published to a **Topic**
- Message is also called an **Event**

---

### Message Definition

â†’ A message represents a **record of a real-world event**  
â†’ Captured at a **particular point in time**

Example:
- User clicked a button
- Sensor reported temperature

---

## âœ… Summary

- Structured Streaming supports append, update, and complete modes
- Event-time processing handles late data using watermarks
- Kafka is a scalable, fault-tolerant messaging system
- Producers publish events; consumers subscribe to topics
- Kafka decouples data producers from consumers
- Communication is language-agnostic
